import { createEffect, createStore, createApi, sample, scopeBind, is, combine, attach, createEvent, step, split, merge } from 'effector';

const unknownContract = {
  isData: raw => true,
  getErrorMessages: () => []
};

function _extends() {
  _extends = Object.assign ? Object.assign.bind() : function (target) {
    for (var i = 1; i < arguments.length; i++) {
      var source = arguments[i];

      for (var key in source) {
        if (Object.prototype.hasOwnProperty.call(source, key)) {
          target[key] = source[key];
        }
      }
    }

    return target;
  };
  return _extends.apply(this, arguments);
}

function _objectWithoutPropertiesLoose(source, excluded) {
  if (source == null) return {};
  var target = {};
  var sourceKeys = Object.keys(source);
  var key, i;

  for (i = 0; i < sourceKeys.length; i++) {
    key = sourceKeys[i];
    if (excluded.indexOf(key) >= 0) continue;
    target[key] = source[key];
  }

  return target;
}

function _toPrimitive(input, hint) {
  if (typeof input !== "object" || input === null) return input;
  var prim = input[Symbol.toPrimitive];

  if (prim !== undefined) {
    var res = prim.call(input, hint || "default");
    if (typeof res !== "object") return res;
    throw new TypeError("@@toPrimitive must return a primitive value.");
  }

  return (hint === "string" ? String : Number)(input);
}

function _toPropertyKey(arg) {
  var key = _toPrimitive(arg, "string");

  return typeof key === "symbol" ? key : String(key);
}

function mapValues(val, fn) {
  const mappedEntries = Object.entries(val).map(([key, value]) => [key, fn(value)]);
  return Object.fromEntries(mappedEntries);
}

function zipObject(object) {
  const result = {};

  for (const [key, value] of Object.entries(object)) {
    for (const [k, v] of Object.entries(value)) {
      result[k] = _extends({}, result[k], {
        [key]: v
      });
    }
  }

  return result;
}

function randomNumber({
  min,
  max
}) {
  return Math.random() * (max - min) + min;
}

/**
 * Copy-pasted, original author is https://github.com/AlexandrHoroshih
 */

/**
 * Creates defer - controlled promise
 */
function createDefer() {
  const defer = {
    // eslint-disable-next-line @typescript-eslint/no-empty-function
    resolve: () => {},
    // eslint-disable-next-line @typescript-eslint/no-empty-function
    reject: () => {},
    // @ts-expect-error it will be set later
    promise: null
  };
  defer.promise = new Promise((rs, rj) => {
    defer.resolve = rs;
    defer.reject = rj;
  }); // eslint-disable-next-line @typescript-eslint/no-empty-function

  defer.promise.catch(() => {});
  return defer;
}

function isEmpty(v) {
  return v == undefined;
}
function isNotEmpty(v) {
  return !isEmpty(v);
}

// Source: https://github.com/smelukov/nano-equal
function isEqual(a, b) {
  try {
    if (a === b) {
      return true;
    }

    if (Number.isNaN(a) && Number.isNaN(b)) {
      return true;
    }

    const typeA = getType(a);
    const typeB = getType(b);

    if (typeA !== typeB) {
      return false;
    }

    if (typeA === 'pure-object') {
      if (a === b) {
        return true;
      }

      const keysA = Object.keys(a);
      const keysBLength = Object.keys(b).length;

      if (keysA.length !== keysBLength) {
        return false;
      }

      for (let i = 0, l = keysA.length; i < l; i++) {
        const key = keysA[i];

        if (!Object.prototype.hasOwnProperty.call(b, keysA[i])) {
          return false;
        }

        const valA = a[key];
        const valB = b[key]; // handle recursion

        if (valA === a || valB === b || valA === b || valB === a) {
          return valA === valB;
        }

        if (!isEqual(valA, valB)) {
          return false;
        }
      }

      return true;
    } else if (typeA === 'array') {
      if (a.length === b.length) {
        for (let j = 0; j < a.length; j++) {
          const elA = a[j];
          const elB = b[j]; // handle recursion

          if (elA === a || elB === b || elA === b || elB === a) {
            return elA === elB;
          }

          if (!isEqual(elA, elB)) {
            return false;
          }
        }
      } else {
        return false;
      }

      return true;
    } else if (typeA === 'object') {
      if (a.valueOf && b.valueOf) {
        return a.valueOf() === b.valueOf();
      }
    }
  } catch (e) {// We got extremely weird objects, let us skip it and consider them not equal
  }

  return false;
}

function isArrayLike(a) {
  if (Array.isArray(a)) {
    return true;
  }

  const len = a.length;

  if (typeof len === 'number' && len > -1) {
    if (len) {
      return 0 in a && len - 1 in a;
    }

    return true;
  }

  return false;
}

function getType(a) {
  const type = typeof a;

  if (type === 'object') {
    if (a === null) {
      return 'null';
    } else if (isArrayLike(a)) {
      return 'array';
    } else if (a.constructor === Object || Object.getPrototypeOf(a) === null) {
      return 'pure-object';
    }

    return 'object';
  }

  return type;
}

function divide(items, predicate) {
  const left = [];
  const right = [];

  for (const item of items) {
    if (predicate(item)) {
      left.push(item);
    } else {
      right.push(item);
    }
  }

  return [left, right];
}

function get(path) {
  return obj => obj[path];
}

function uniq(array) {
  return Array.from(new Set(array));
}

/*
 * Inspired by https://github.com/DirtyHairy/async-mutex
 */
class Mutex {
  constructor() {
    this._resolve = null;
    this._promise = Promise.resolve();
  }

  get isLocked() {
    return !!this._resolve;
  }

  acquire() {
    if (this.isLocked) {
      return;
    }

    this._promise = new Promise(res => {
      this._resolve = res;
    });
  }

  waitForUnlock() {
    return this._promise;
  }

  release() {
    if (this._resolve) {
      this._resolve();

      this._resolve = null;
    }
  }

}

const INVALID_DATA = 'INVALID_DATA';
const TIMEOUT = 'TIMEOUT';
const ABORT = 'ABORT';
const PREPARATION = 'PREPARATION';
const HTTP = 'HTTP';
const NETWORK = 'NETWORK';
const CONFIGURATION = 'CONFIGURATION';

function invalidDataError(config) {
  return _extends({}, config, {
    errorType: INVALID_DATA,
    explanation: 'Response was considered as invalid against a given contract'
  });
}
function timeoutError(config) {
  return _extends({}, config, {
    errorType: TIMEOUT,
    explanation: 'Request was cancelled due to timeout'
  });
}
function abortError() {
  return {
    errorType: ABORT,
    explanation: 'Request was cancelled due to concurrency policy'
  };
}
function preparationError(config) {
  return _extends({}, config, {
    errorType: PREPARATION,
    explanation: 'Extraction of data from the response was failed'
  });
}
function httpError(config) {
  return _extends({}, config, {
    errorType: HTTP,
    explanation: 'Request was finished with unsuccessful HTTP code'
  });
}
function networkError(config) {
  return _extends({}, config, {
    errorType: NETWORK,
    explanation: 'Request was failed due to network problems'
  });
}
function configurationError(config) {
  return _extends({}, config, {
    errorType: CONFIGURATION,
    explanation: 'Operation is misconfigured'
  });
}

let count = 0;

const getId = () => {
  count += 1;
  return count;
};

const createAborter = () => {
  let handlers = [];

  const onAbort = fn => {
    handlers.push(fn);
    return () => {
      const idx = handlers.findIndex(f => f === fn);

      if (idx > -1) {
        handlers.splice(idx, 1);
      }
    };
  };

  const runAborters = () => {
    handlers.forEach(f => f());
    handlers = [];
  };

  return {
    runAborters,
    onAbort
  };
};

const createCall = ctx => {
  const def = createDefer();
  def.context = ctx;
  return def;
};

function abortable(config) {
  var _a, _b;

  const {
    abort,
    effect
  } = config;
  const runCallFx = createEffect(async def => {
    const result = await def.promise;
    return result;
  });
  const $calls = createStore([], {
    serialize: 'ignore',
    name: 'ff.$calls',
    sid: 'ff.$calls'
  });
  const callsApi = createApi($calls, {
    add(calls, def) {
      return [...calls, def];
    },

    remove(calls, def) {
      return calls.filter(d => d !== def);
    }

  });

  if (abort === null || abort === void 0 ? void 0 : abort.signal) {
    const cancelAllFx = createEffect(calls => {
      calls.forEach(c => {
        var _a, _b;

        (_b = (_a = c.context) === null || _a === void 0 ? void 0 : _a.runAborters) === null || _b === void 0 ? void 0 : _b.call(_a);
        c.reject(abortError());
      });
    });
    sample({
      clock: abort.signal,
      source: $calls,
      target: cancelAllFx
    });
  } // нужно, чтобы поддержать и синхронные эффекты тоже


  const handler = async (...args) => effect(...args);

  const runnerFx = createEffect({
    name: (_a = config.name) !== null && _a !== void 0 ? _a : 'runnerFx',
    sid: ((_b = config.name) !== null && _b !== void 0 ? _b : 'runnerFx') + getId(),
    handler: async p => {
      const {
        runAborters,
        onAbort
      } = createAborter();
      const call = createCall({
        runAborters
      });
      callsApi.add(call);
      let boundApiRemove;

      try {
        boundApiRemove = scopeBind(callsApi.remove);
      } catch (e) {
        boundApiRemove = callsApi.remove;
      }

      handler(p, {
        onAbort
      }).then(call.resolve).catch(call.reject).finally(() => boundApiRemove(call));
      const result = await runCallFx(call);
      return result;
    }
  });
  return runnerFx;
}

function normalizeSourced({
  field
}) {
  let $target;

  if (field === undefined) {
    // do nothing
    $target = createStore(_ => null, {
      serialize: 'ignore',
      name: 'ff.$target/undefined',
      sid: 'ff.$target/undefined'
    });
  } else if (is.store(field)) {
    const $storeField = field;
    $target = combine($storeField, fieldValue => _ => fieldValue !== null && fieldValue !== void 0 ? fieldValue : null);
  } else if ((field === null || field === void 0 ? void 0 : field.source) && (field === null || field === void 0 ? void 0 : field.fn)) {
    const callbackField = field;
    $target = combine(callbackField.source, source => params => {
      var _a;

      return (_a = callbackField.fn(params, source)) !== null && _a !== void 0 ? _a : null;
    });
  } else if (typeof field === 'function') {
    const callbackField = field;
    $target = createStore(params => {
      var _a;

      return (_a = callbackField(params)) !== null && _a !== void 0 ? _a : null;
    }, {
      serialize: 'ignore',
      name: 'ff.$target/callbackField',
      sid: 'ff.$target/$callbackField'
    });
  } else {
    const valueField = field;
    $target = createStore(_ => valueField !== null && valueField !== void 0 ? valueField : null, {
      serialize: 'ignore',
      name: 'ff.$target/valueField',
      sid: 'ff.$target/$valueField'
    });
  }

  return $target;
} // -- Reader case --


function createSourcedReader(field) {
  let readFx;

  if (field === undefined) {
    readFx = createEffect(async _params => null);
  } else if (is.store(field)) {
    const $storeField = field;
    readFx = attach({
      source: $storeField,

      async effect(source, _params) {
        return source;
      }

    });
  } else if (field.source && field.fn) {
    const callbackField = field;
    readFx = attach({
      source: callbackField.source,

      async effect(source, params) {
        return callbackField.fn(params, source);
      }

    });
  } else if (typeof field === 'function') {
    const callbackField = field;
    readFx = createEffect(async params => callbackField(params));
  } else {
    const valueField = field;
    readFx = createEffect(async _params => valueField);
  }

  return readFx;
}

function normalizeStaticOrReactive(v) {
  if (!v) {
    return createStore(null, {
      serialize: 'ignore',
      name: 'ff.$target/undefined',
      sid: 'ff.$target/$undefined'
    });
  }

  if (is.store(v)) {
    return v;
  }

  return createStore(v, {
    serialize: 'ignore',
    name: 'ff.$target/valueField',
    sid: 'ff.$target/$valueField'
  });
} // -- Extract source


function extractSource(sourced) {
  if (is.store(sourced)) {
    return sourced;
  }

  if (sourced === null || sourced === void 0 ? void 0 : sourced.source) {
    return sourced.source;
  }

  return null;
} // -- Combine sourced


function combineSourced(config, mapper) {
  const megaStore = {};
  const megaFns = {};

  for (const [key, value] of Object.entries(config)) {
    if (is.store(value)) {
      megaStore[key] = value;
    } else if ((value === null || value === void 0 ? void 0 : value.source) && (value === null || value === void 0 ? void 0 : value.fn)) {
      megaStore[key] = value.source;
      megaFns[key] = value.fn;
    } else if (typeof value === 'function') {
      megaFns[key] = value;
    } else {
      // plain value
      megaStore[key] = value;
    }
  }

  const $megaSource = combine(megaStore);
  return {
    source: $megaSource,
    fn: (data, source) => {
      const result = {};

      for (const key of Object.keys(config)) {
        if (key in source) {
          result[key] = source[key];
        }

        if (key in megaFns) {
          result[key] = megaFns[key](data, source[key]);
        }
      }

      if (mapper) {
        return mapper(result);
      } else {
        return result;
      }
    }
  };
} // -- Exports --

function delay({
  clock,
  timeout,
  target = createEvent()
}) {
  const timerFx = createEffect(({
    payload,
    milliseconds
  }) => new Promise(resolve => {
    setTimeout(resolve, milliseconds, payload);
  }));
  sample({
    source: normalizeStaticOrReactive(timeout),
    clock,
    fn: (milliseconds, payload) => ({
      payload,
      milliseconds
    }),
    target: timerFx
  });
  sample({
    clock: timerFx.doneData,
    target: target
  });
  return target;
}

function every(configOrStores, predicateOrNone) {
  let stores = [];

  let predicate = () => false;

  if (Array.isArray(configOrStores)) {
    stores = configOrStores;
    predicate = predicateOrNone;
  } else if (Array.isArray(configOrStores.stores)) {
    stores = configOrStores.stores;
    predicate = configOrStores.predicate;
  }

  let checker;

  if (isFunction(predicate)) {
    checker = predicate;
  } else if (is.store(predicate)) {
    checker = predicate.map(value => required => value === required);
  } else {
    checker = value => value === predicate;
  }

  const $values = combine(stores); // Combine pass simple values as is

  const $checker = checker;
  return combine($checker, $values, (checker, values) => values.every(checker));
}

function isFunction(value) {
  return typeof value === 'function';
}

function not(source) {
  return source.map(value => !value);
}

function and(...stores) {
  return every({
    predicate: true,
    stores
  });
}

/**
 * Откладывает выполнение события до переданного указанного стора в состояние `true`
 *
 * @returns событие, которое будет вызывано после вызова clock, когда until будет true
 */

function postpone({
  clock,
  until
}) {
  const target = createEvent();
  const $fired = createStore(false, {
    serialize: 'ignore',
    name: 'ff.$fired',
    sid: 'ff.$fired'
  }).on(target, () => true).on(clock, () => false);
  sample({
    clock: [clock, until],
    source: clock,
    filter: and(until, not($fired)),
    target
  });
  return target;
}

function serializationForSideStore(serialize) {
  if (serialize === 'ignore') {
    return 'ignore';
  }

  return undefined;
}

const readNowFx = createEffect(() => Date.now());
function time({
  clock
}) {
  const $time = createStore(Date.now(), {
    name: 'ff.$time',
    sid: 'ff.$time'
  });
  sample({
    clock: clock,
    fn: () => {// nothing
    },
    target: readNowFx
  });
  sample({
    clock: readNowFx.doneData,
    target: $time
  });
  return $time;
}

function readonly(storeOrEvent) {
  return storeOrEvent.map(v => v, {
    skipVoid: false
  });
}

// Copied and adopted https://github.com/effector/patronum/blob/main/src/debounce/index.ts
function syncBatch(clock) {
  const saveTimeoutId = createEvent();
  const $timeoutId = createStore(null, {
    serialize: 'ignore',
    name: 'ff.$timeoutId',
    sid: 'ff.$timeoutId'
  }).on(saveTimeoutId, (_, id) => id);
  const saveReject = createEvent();
  const $rejecter = createStore(null, {
    serialize: 'ignore',
    name: 'ff.$rejecter',
    sid: 'ff.$rejecter'
  }).on(saveReject, (_, rj) => rj);
  const tick = createEvent();
  const timerFx = attach({
    source: {
      timeoutId: $timeoutId,
      rejectPromise: $rejecter
    },
    effect: ({
      timeoutId,
      rejectPromise
    }) => {
      if (timeoutId) clearTimeout(timeoutId);
      if (rejectPromise) rejectPromise();
      return new Promise((resolve, reject) => {
        saveReject(reject);
        saveTimeoutId(setTimeout(resolve, 0));
      });
    }
  });
  $rejecter.reset(timerFx.done);
  $timeoutId.reset(timerFx.done); // It's ok - nothing will ever start unless source is triggered

  const $payload = createStore([], {
    serialize: 'ignore',
    name: 'ff.$payload',
    sid: 'ff.$payload'
  }).on(clock, (_, payload) => [payload]);
  const $canTick = createStore(true, {
    serialize: 'ignore',
    sid: 'ff.$canTick',
    name: 'ff.$canTick'
  });
  const triggerTick = createEvent();
  $canTick.on(triggerTick, () => false).on([tick, // debounce timeout can be restarted in later ticks
  timerFx], () => true);
  sample({
    clock: clock,
    filter: $canTick,
    target: triggerTick
  });
  sample({
    clock: triggerTick,
    target: timerFx
  });
  sample({
    source: $payload,
    clock: timerFx.done,
    fn: ([payload]) => payload,
    target: tick
  });
  return tick;
}

function combineEvents({
  events,
  reset
}) {
  const target = createEvent();
  const $doneEventIndexes = createStore([], {
    serialize: 'ignore'
  });

  if (reset) {
    sample({
      clock: reset,
      target: $doneEventIndexes.reinit
    });
  }

  events.forEach((event, idx) => {
    $doneEventIndexes.on(event, indexes => uniq([...indexes, idx]));
  });
  sample({
    clock: events,
    source: $doneEventIndexes,
    filter: indexes => indexes.length === events.length,
    target
  });
  return target;
}

function createContractApplier(contract) {
  const applyContractFx = createEffect({
    handler: ({
      result: data
    }) => {
      const isData = contract.isData(data);

      if (!isData) {
        throw invalidDataError({
          validationErrors: contract.getErrorMessages(data),
          response: data
        });
      }

      return data;
    },
    sid: 'ff.applyContractFx'
  });
  return applyContractFx;
}

function checkValidationResult(result) {
  if (result === true) {
    return true;
  }

  if (Array.isArray(result) && result.length === 0) {
    return true;
  }

  if (typeof result === 'string' && result.length === 0) {
    return true;
  }

  return false;
}

function unwrapValidationResult(result) {
  if (result === true) {
    return [];
  }

  if (result === false) {
    return ['Invalid data'];
  }

  if (!Array.isArray(result)) {
    return [result];
  }

  if (result.length === 0) {
    return [];
  }

  return result;
}

const validValidator = () => true;

function isInvalidDataError(args) {
  var _a;

  return ((_a = args.error) === null || _a === void 0 ? void 0 : _a.errorType) === INVALID_DATA;
}
function isTimeoutError(args) {
  var _a;

  return ((_a = args.error) === null || _a === void 0 ? void 0 : _a.errorType) === TIMEOUT;
}
/**
 * Has to be private, do not export it.
 *
 * Since Farfetcehd 0.10 aborted RemoteOperation is not considered as an error,
 * so isAbortError is not needed anymore in userland.
 */

function isAbortError(args) {
  var _a;

  return ((_a = args.error) === null || _a === void 0 ? void 0 : _a.errorType) === ABORT;
}
function isPreparationError(args) {
  var _a;

  return ((_a = args.error) === null || _a === void 0 ? void 0 : _a.errorType) === PREPARATION;
}
function isHttpError(args) {
  var _a;

  return ((_a = args.error) === null || _a === void 0 ? void 0 : _a.errorType) === HTTP;
}
function isHttpErrorCode(code) {
  return function isExactHttpError(args) {
    if (!isHttpError(args)) {
      return false;
    }

    const codes = Array.isArray(code) ? code : [code];
    return codes.includes(args.error.status);
  };
}
function isNetworkError(args) {
  var _a;

  return ((_a = args.error) === null || _a === void 0 ? void 0 : _a.errorType) === NETWORK;
}

/**
 *
 * Patches effect handler to emit call object for each call of the effect,
 * each call object provides low level control over the call
 *
 * @param effect - Effect to patch
 * @returns event that emits call object for each call of the effect
 */

function getCallObjectEvent(effect) {
  const called = createEvent(effect.shortName + '.internalCall');
  const callObjStep = step.compute({
    fn: run => {
      const originalHandler = run.handler;
      const patchedHandler = createPatchedHandler(originalHandler, called);
      run.handler = patchedHandler;
      return run;
    }
  });
  const runner = getEffectRunnerNode(effect);
  /**
   * First steps of the runner: resolve of params and handler
   * Last step is execution of the handler
   *
   * Insertion of the patched handler step must happen right before execution of the handler itself,
   * after everything else is resolved
   *
   * @see https://github.com/effector/effector/blob/a0f997b3d355c5a9b682e3747f00a1ffe7de8646/src/effector/__tests__/effect/index.test.ts#L432
   */

  runner.seq.splice(1, 0, callObjStep);
  return called;
}

function createPatchedHandler(h, calledEvent) {
  function ffMagicHandler(...p) {
    /**
     * Normal flow of the handler,
     * its result is reflected to the outside world
     */
    const result = h(...p);

    if (result instanceof Promise) {
      /**
       * Async handlers are patched to emit call object,
       * which provides low level control over the call
       */
      const def = createDefer();
      const callObj = createCallObject(def);
      calledEvent(callObj);
      result.then(def.resolve, def.reject);
      return def.promise;
    } else {
      /**
       * It is not possible to control sync handlers at all, because their execution is instant
       * So call object is emitted as "finished" right away
       */
      const callObj = createCallObject();
      calledEvent(callObj);
      return result;
    }
  }

  return ffMagicHandler;
}

function createCallObject(def) {
  let callStatus = def ? 'pending' : 'finished';

  function finish() {
    callStatus = 'finished';
    callObj.status = callStatus;
  }

  if (def) {
    def.promise.then(finish, finish);
  }

  const callObj = {
    id: getCallId(),
    status: callStatus,
    abort: (error = abortError()) => {
      if (callStatus === 'finished') {
        /**
         * It is not possible to abort already finished call,
         * so nothing happens
         */
        return;
      }

      if (def) {
        def.reject(error);
      }
    },
    promise: def === null || def === void 0 ? void 0 : def.promise
  };
  return callObj;
}

function getEffectRunnerNode(effect) {
  const runner = effect.graphite.scope.runner;
  return runner;
}

let n = 0;

function getCallId() {
  const id = `${n++}`;
  return id;
}

function createRemoteOperation({
  name: ownName,
  meta,
  kind,
  serialize,
  enabled,
  contract,
  validate,
  mapData,
  sourced,
  paramsAreMeaningless
}) {
  const revalidate = createEvent();
  const pushData = createEvent();
  const pushError = createEvent();
  const startWithMeta = createEvent();
  const applyContractFx = createContractApplier(contract);
  const name = ownName !== null && ownName !== void 0 ? ownName : 'unnamed'; // Dummy effect, it will be replaced with real in head-full factory

  const executeFx = createEffect({
    handler: () => {
      throw new Error('Not implemented');
    },
    sid: `ff.${name}.executeFx`,
    name: `${name}.executeFx`
  });
  const callObjectCreated = getCallObjectEvent(executeFx);
  const remoteDataSoruce = {
    name: 'remote_source',
    get: createEffect(async ({
      params
    }) => {
      const result = await executeFx(params);
      return {
        result,
        stale: false
      };
    })
  };
  const dataSources = [remoteDataSoruce];
  const {
    retrieveDataFx,
    notifyAboutNewValidDataFx,
    notifyAboutDataInvalidationFx
  } = createDataSourceHandlers(dataSources);
  const start = createEvent();
  const started = createEvent();
  sample({
    clock: start,
    fn: params => ({
      params,
      meta: {
        stopErrorPropagation: false,
        stale: true
      }
    }),
    target: startWithMeta
  }); // Signal-events

  const finished = {
    success: createEvent(),
    failure: createEvent(),
    skip: createEvent(),
    finally: createEvent()
  };
  const failedNoFilters = createEvent();
  const aborted = createEvent();
  split({
    source: failedNoFilters,
    match: {
      aborted: ({
        error
      }) => isAbortError({
        error
      })
    },
    cases: {
      aborted,
      __: finished.failure
    }
  }); // -- Main stores --

  const $status = createStore('initial', {
    sid: `ff.${name}.$status`,
    name: `ff.${name}.$status`,
    serialize
  });
  const resetStatus = createEvent();
  sample({
    clock: resetStatus,
    target: $status.reinit
  });
  const $statusHistory = createStore([], {
    serialize: 'ignore',
    name: `ff.${name}.$statusHistory`,
    sid: `ff.${name}.$statusHistory`
  });
  sample({
    clock: $status.updates,
    source: $statusHistory,
    fn: (history, nextStatus) => [...history, nextStatus],
    target: $statusHistory
  });
  const $enabled = normalizeStaticOrReactive(enabled !== null && enabled !== void 0 ? enabled : true).map(Boolean);
  const $latestParams = createStore(undefined, {
    serialize: 'ignore',
    name: `ff.${name}.$latestParams`,
    sid: `ff.${name}.$latestParams`,
    skipVoid: false
  }); // -- Derived stores --

  const $idle = $status.map(status => status === 'initial');
  const $pending = $status.map(status => status === 'pending');
  const $failed = $status.map(status => status === 'fail');
  const $succeeded = $status.map(status => status === 'done');
  const $finished = $status.map(status => ['fail', 'done'].includes(status)); // -- Indicate status --

  sample({
    clock: [retrieveDataFx.map(() => 'pending'), finished.success.map(() => 'done'), finished.failure.map(() => 'fail'), sample({
      clock: aborted,
      source: {
        history: $statusHistory,
        retrieveDataPengind: retrieveDataFx.pending
      },
      fn: ({
        history,
        retrieveDataPengind
      }) => {
        var _a;

        if (retrieveDataPengind) {
          return 'pending';
        }

        return (_a = history[history.length - 2]) !== null && _a !== void 0 ? _a : 'initial';
      }
    })],
    target: $status
  });
  sample({
    clock: startWithMeta,
    filter: $enabled,
    fn: ({
      params
    }) => params,
    target: $latestParams
  }); // -- Execution flow

  sample({
    clock: start,
    filter: not($enabled),

    fn(params) {
      return {
        params,
        meta: {
          stopErrorPropagation: false,
          stale: false
        }
      };
    },

    target: finished.skip
  });
  sample({
    clock: revalidate,
    fn: ({
      params
    }) => ({
      params,
      meta: {
        stopErrorPropagation: false,
        stale: true
      }
    }),
    target: notifyAboutDataInvalidationFx
  });
  sample({
    clock: notifyAboutDataInvalidationFx.finally,
    source: revalidate,
    filter: ({
      refresh
    }) => refresh,
    fn: ({
      params
    }) => ({
      params,
      meta: {
        stopErrorPropagation: false,
        stale: true
      }
    }),
    target: startWithMeta
  });
  sample({
    clock: startWithMeta,
    filter: $enabled,
    target: retrieveDataFx
  });
  sample({
    clock: retrieveDataFx,
    target: started
  });
  sample({
    clock: retrieveDataFx.done,
    fn: ({
      params,
      result
    }) => ({
      params: params.params,
      result: result.result,
      meta: {
        stopErrorPropagation: false,
        stale: result.stale
      }
    }),
    filter: $enabled,
    target: applyContractFx
  });
  sample({
    clock: retrieveDataFx.fail,
    source: $enabled,
    filter: (enabled, {
      error
    }) => enabled && !error.stopErrorPropagation,
    fn: (_, {
      error,
      params
    }) => ({
      error: error.error,
      params: params.params,
      meta: {
        stopErrorPropagation: error.stopErrorPropagation,
        stale: false
      }
    }),
    target: failedNoFilters
  });
  const {
    validDataRecieved,
    __: invalidDataRecieved
  } = split(sample({
    clock: applyContractFx.done,
    source: {
      partialValidator: normalizeSourced({
        field: validate !== null && validate !== void 0 ? validate : validValidator
      })
    },
    fn: ({
      partialValidator
    }, {
      params: {
        /* Extract original params, it is params of params */
        params,
        meta
      },
      result
    }) => ({
      result,
      params,
      validation: partialValidator({
        result,
        params
      }),
      meta
    })
  }), {
    validDataRecieved: ({
      validation
    }) => checkValidationResult(validation)
  });
  sample({
    clock: validDataRecieved,
    source: {
      partialMapper: normalizeSourced({
        field: mapData
      })
    },
    fn: ({
      partialMapper
    }, {
      params,
      result,
      meta
    }) => ({
      result: partialMapper({
        params,
        result
      }),
      params,
      meta
    }),
    target: finished.success
  });
  sample({
    clock: finished.success,
    filter: ({
      meta
    }) => meta.stale,
    fn: ({
      params,
      meta
    }) => ({
      params,
      meta,
      skipStale: true
    }),
    target: retrieveDataFx
  });
  sample({
    clock: validDataRecieved,
    filter: ({
      meta
    }) => !meta.stale,
    target: notifyAboutNewValidDataFx
  });
  sample({
    clock: applyContractFx.fail,
    filter: ({
      params
    }) => !params.meta.stopErrorPropagation,
    fn: ({
      error,
      params
    }) => ({
      error,
      // Extract original params, it is params of params
      params: params.params,
      meta: params.meta
    }),
    target: failedNoFilters
  });
  sample({
    clock: invalidDataRecieved,
    filter: ({
      meta
    }) => !meta.stopErrorPropagation,
    fn: ({
      params,
      validation,
      meta,
      result
    }) => ({
      params,
      error: invalidDataError({
        validationErrors: unwrapValidationResult(validation),
        response: result
      }),
      meta
    }),
    target: failedNoFilters
  }); // Emit skip for disabling in-flight operation

  sample({
    clock: $enabled.updates,
    source: start,
    filter: not($enabled),
    fn: params => ({
      params,
      meta: {
        stopErrorPropagation: false,
        stale: true
      }
    }),
    target: finished.skip
  }); // -- Send finally --

  sample({
    clock: finished.success,
    fn: ({
      params,
      result,
      meta
    }) => ({
      status: 'done',
      params,
      result,
      meta
    }),
    target: finished.finally
  });
  sample({
    clock: finished.failure,
    fn: ({
      params,
      error,
      meta
    }) => ({
      status: 'fail',
      params,
      error,
      meta
    }),
    target: finished.finally
  });
  sample({
    clock: finished.skip,
    fn: ({
      params,
      meta
    }) => ({
      status: 'skip',
      params,
      meta
    }),
    target: finished.finally
  });
  return {
    start,
    finished,
    started,
    aborted,
    $status,
    $idle,
    $pending,
    $failed,
    $succeeded,
    $finished,
    $enabled,
    __: {
      executeFx,
      meta: _extends({}, meta, {
        name
      }),
      kind,
      $latestParams: readonly($latestParams),
      lowLevelAPI: {
        dataSources,
        dataSourceRetrieverFx: retrieveDataFx,
        sourced: sourced !== null && sourced !== void 0 ? sourced : [],
        paramsAreMeaningless: paramsAreMeaningless !== null && paramsAreMeaningless !== void 0 ? paramsAreMeaningless : false,
        revalidate,
        pushError,
        pushData,
        startWithMeta,
        callObjectCreated,
        resetStatus
      }
    }
  };
}

function createDataSourceHandlers(dataSources) {
  const retrieveDataFx = createEffect({
    handler: async ({
      params,
      skipStale
    }) => {
      for (const dataSource of dataSources) {
        try {
          const fromSource = await dataSource.get({
            params
          });

          if (skipStale && (fromSource === null || fromSource === void 0 ? void 0 : fromSource.stale)) {
            continue;
          }

          if (fromSource) {
            return fromSource;
          }
        } catch (error) {
          throw {
            stopErrorPropagation: false,
            error
          };
        }
      }

      throw {
        stopErrorPropagation: false,
        error: new Error('No data source returned data')
      };
    }
  });
  const notifyAboutNewValidDataFx = createEffect({
    handler: async ({
      params,
      result
    }) => {
      await Promise.all(dataSources.map(get('set')).filter(Boolean).map(set => set({
        params,
        result
      })));
    }
  });
  const notifyAboutDataInvalidationFx = createEffect({
    handler: async ({
      params
    }) => {
      await Promise.all(dataSources.map(get('unset')).filter(Boolean).map(unset => unset({
        params
      })));
    }
  });
  return {
    retrieveDataFx,
    notifyAboutNewValidDataFx,
    notifyAboutDataInvalidationFx
  };
}

const QuerySymbol = Symbol('Query');
function isQuery(value) {
  var _a;

  return ((_a = value === null || value === void 0 ? void 0 : value.__) === null || _a === void 0 ? void 0 : _a.kind) === QuerySymbol;
}

const _excluded$2 = ["params"];
/**
 * Creates Query without any executor, it cannot be used as-is.
 *
 * @example
 * const headlessQuery = createHeadlessQuery()
 * headlessQuery.__.executeFx.use(someHandler)
 */

function createHeadlessQuery(config) {
  const {
    initialData: initialDataRaw,
    contract,
    mapData,
    enabled,
    validate,
    name,
    serialize,
    sourced,
    paramsAreMeaningless
  } = config;
  const initialData = initialDataRaw !== null && initialDataRaw !== void 0 ? initialDataRaw : null;
  const operation = createRemoteOperation({
    name,
    kind: QuerySymbol,
    serialize: serializationForSideStore(serialize),
    enabled,
    meta: {
      serialize,
      initialData,
      sid: querySid$1(createStore(null, {
        sid: 'dummy'
      }))
    },
    contract,
    validate,
    mapData,
    sourced,
    paramsAreMeaningless
  });
  const refresh = createEvent();
  const reset = createEvent(); // -- Main stores --

  const $data = createStore(initialData, {
    sid: `ff.${operation.__.meta.name}.$data`,
    name: `${operation.__.meta.name}.$data`,
    serialize,
    skipVoid: false
  });
  const $error = createStore(null, {
    sid: `ff.${operation.__.meta.name}.$error`,
    name: `${operation.__.meta.name}.$error`,
    serialize: serializationForSideStore(serialize),
    skipVoid: false
  });
  const $stale = createStore(true, {
    sid: `ff.${operation.__.meta.name}.$stale`,
    name: `${operation.__.meta.name}.$stale`,
    serialize: serializationForSideStore(serialize),
    skipVoid: false
  });
  sample({
    clock: operation.finished.success,
    fn: () => null,
    target: $error
  });
  sample({
    clock: operation.finished.success,
    fn: ({
      result
    }) => result,
    target: $data
  });
  $data.reset(operation.finished.failure);
  sample({
    clock: operation.finished.failure,
    fn: ({
      error
    }) => error,
    target: $error
  }); // -- Handle stale

  sample({
    clock: operation.finished.finally,
    fn: ({
      meta
    }) => meta.stale,
    target: $stale
  });
  sample({
    clock: operation.__.lowLevelAPI.pushData,
    target: [$data, $error.reinit]
  });
  sample({
    clock: operation.__.lowLevelAPI.pushError,
    target: [$error, $data.reinit]
  }); // -- Trigger API

  const postponedRefresh = postpone({
    clock: refresh,
    until: operation.$enabled
  });
  const refreshSkipDueToFreshness = createEvent();
  const {
    haveToStart,
    __: haveToSkip
  } = split(sample({
    clock: postponedRefresh,
    source: {
      stale: $stale,
      latestParams: operation.__.$latestParams
    },
    fn: ({
      stale,
      latestParams
    }, params) => ({
      haveToStart: stale || !isEqual(params, latestParams),
      params
    })
  }), {
    haveToStart: ({
      haveToStart
    }) => haveToStart
  });
  sample({
    clock: haveToSkip,
    fn: () => null,
    target: refreshSkipDueToFreshness
  });
  sample({
    clock: haveToStart,
    fn: ({
      params
    }) => params,
    target: operation.start
  }); // -- Reset state --

  sample({
    clock: reset,
    target: [$data.reinit, $error.reinit, $stale.reinit, operation.__.lowLevelAPI.resetStatus]
  }); // -- Protocols --

  const unitShape = {
    data: $data,
    error: $error,
    stale: $stale,
    pending: operation.$pending,
    start: operation.start
  };

  const unitShapeProtocol = () => unitShape; // Experimental API, won't be exposed as protocol for now


  const attachProtocol = ({
    source,
    mapParams
  }) => {
    const attachedQuery = createHeadlessQuery(config);

    attachedQuery.__.lowLevelAPI.dataSourceRetrieverFx.use(attach({
      source,
      mapParams: (_ref, sourceValue) => {
        let {
          params
        } = _ref,
            rest = _objectWithoutPropertiesLoose(_ref, _excluded$2);

        return _extends({
          params: mapParams ? mapParams(params, sourceValue) : params
        }, rest);
      },
      effect: operation.__.lowLevelAPI.dataSourceRetrieverFx
    }));

    return attachedQuery;
  }; // -- Public API --


  return {
    reset,
    refresh,
    start: operation.start,
    started: readonly(operation.started),
    $data: readonly($data),
    $error: readonly($error),
    $status: readonly(operation.$status),
    $idle: readonly(operation.$idle),
    $pending: readonly(operation.$pending),
    $succeeded: readonly(operation.$succeeded),
    $failed: readonly(operation.$failed),
    $finished: readonly(operation.$finished),
    $enabled: readonly(operation.$enabled),
    $stale,
    aborted: readonly(operation.aborted),
    finished: {
      success: readonly(operation.finished.success),
      failure: readonly(operation.finished.failure),
      finally: readonly(operation.finished.finally),
      skip: readonly(operation.finished.skip)
    },
    __: _extends({}, operation.__, {
      lowLevelAPI: _extends({}, operation.__.lowLevelAPI, {
        refreshSkipDueToFreshness
      }),
      experimentalAPI: {
        attach: attachProtocol
      }
    }),
    '@@unitShape': unitShapeProtocol
  };
}

function querySid$1($data) {
  const sid = $data.sid;

  if (!(sid === null || sid === void 0 ? void 0 : sid.includes('|'))) {
    return null;
  }

  return sid;
}

function resolveExecuteEffect(config) {
  const anyConfig = config;

  if (is.effect(anyConfig.effect)) {
    return anyConfig.effect;
  } else if (typeof anyConfig.handler === 'function') {
    return createEffect(anyConfig.handler);
  }

  throw new InvalidConfigException('handler or effect must be passed to the config');
}

class InvalidConfigException extends Error {
  constructor(message) {
    super(message);
  }

}

function createQuery( // Use any because of overloads
// eslint-disable-next-line @typescript-eslint/no-explicit-any
config) {
  var _a, _b, _c;

  const query = createHeadlessQuery({
    initialData: (_a = config.initialData) !== null && _a !== void 0 ? _a : null,
    contract: (_b = config.contract) !== null && _b !== void 0 ? _b : unknownContract,
    mapData: (_c = config.mapData) !== null && _c !== void 0 ? _c : ({
      result
    }) => result,
    enabled: config.enabled,
    validate: config.validate,
    name: config.name,
    serialize: config.serialize
  });

  query.__.executeFx.use(resolveExecuteEffect(config));

  return query;
}

function connectQuery(args) {
  const {
    source,
    target
  } = args; // Settings

  const singleParentMode = isQuery(source); // Participants

  const children = Array.isArray(target) ? target : [target];
  const parents = singleParentMode ? [source] : Object.values(source);
  const mapperFn = args === null || args === void 0 ? void 0 : args.fn; // Helper untis

  const anyParentStarted = merge(parents.map(query => query.start));
  const anyParentSuccessfullyFinished = merge(parents.map(query => query.finished.success));
  const $allParentsHaveData = every({
    stores: parents.map(query => query.$data),
    predicate: data => data !== null
  });
  const $allParentDataDictionary = singleParentMode ? source.$data : combine(mapValues(source, query => query.$data));
  const $allParentParamsDictionary = createStore(null, {
    serialize: 'ignore',
    name: 'ff.$allParentParamsDictionary',
    sid: 'ff.$allParentParamsDictionary',
    skipVoid: false
  });

  if (singleParentMode) {
    sample({
      clock: source.finished.success,
      fn: ({
        params
      }) => params,
      target: $allParentParamsDictionary
    });
  } else {
    for (const [parentName, parentFinishedSuccess] of Object.entries(mapValues(source, query => query.finished.success))) {
      sample({
        clock: parentFinishedSuccess,
        source: $allParentParamsDictionary,
        fn: (latestParams, {
          params
        }) => _extends({}, latestParams, {
          [parentName]: params
        }),
        target: $allParentParamsDictionary
      });
    }
  } // Relations


  sample({
    clock: anyParentStarted,

    fn() {
      return true;
    },

    target: children.map(t => t.$stale)
  });
  sample({
    clock: postpone({
      clock: anyParentSuccessfullyFinished,
      until: $allParentsHaveData
    }),
    source: {
      data: $allParentDataDictionary,
      params: $allParentParamsDictionary
    },

    fn({
      data,
      params
    }) {
      const mapped = mapperFn === null || mapperFn === void 0 ? void 0 : mapperFn(singleParentMode ? {
        result: data,
        params
      } : zipObject({
        result: data,
        params
      }));
      return mapped === null || mapped === void 0 ? void 0 : mapped.params;
    },

    target: children.map(t => t.start)
  });
}

function mergeRecords(...records) {
  const final = {};

  for (const item of records) {
    if (typeof item !== 'object') {
      continue;
    }

    for (const [key, value] of Object.entries(item || {})) {
      const newCleanValue = clearValue(value);

      if (newCleanValue === null) {
        continue;
      }

      if (final[key]) {
        final[key] = [final[key], newCleanValue].flat();
      } else {
        final[key] = newCleanValue;
      }
    }
  }

  return final;
}
function mergeQueryStrings(...queryStrings) {
  const final = [];

  for (const item of queryStrings) {
    if (!item) {
      continue;
    }

    let curr;

    if (typeof item !== 'string') {
      curr = recordToUrlSearchParams(item).toString();
    } else {
      curr = item;
    }

    final.push(curr);
  }

  return final.join('&');
}
function formatHeaders(headersRecord) {
  const headers = new Headers();

  for (const [key, value] of Object.entries(headersRecord)) {
    const cleanValue = clearValue(value);

    if (Array.isArray(cleanValue)) {
      for (const v of cleanValue) {
        headers.append(key, v);
      }
    } else if (cleanValue !== null) {
      headers.append(key, cleanValue);
    }
  }

  return headers;
}
function formatUrl(url, queryRecord) {
  let urlString;
  let queryString;

  if (typeof queryRecord === 'string') {
    queryString = queryRecord;
  } else {
    queryString = recordToUrlSearchParams(queryRecord).toString();
  }

  if (!queryString) {
    urlString = url;
  } else {
    urlString = `${url}?${queryString}`;
  }

  try {
    return new URL(urlString);
  } catch (e) {
    throw configurationError({
      reason: 'Invalid URL',
      validationErrors: [`"${urlString}" is not valid URL`]
    });
  }
}

function recordToUrlSearchParams(record) {
  const params = new URLSearchParams();

  for (const [key, value] of Object.entries(record)) {
    const cleanValue = clearValue(value);

    if (Array.isArray(cleanValue)) {
      for (const v of cleanValue) {
        params.append(key, v);
      }
    } else if (cleanValue !== null) {
      params.append(key, cleanValue);
    }
  }

  return params;
}

function clearValue(value) {
  if (typeof value === 'number' || typeof value === 'boolean') {
    return value.toString();
  }

  return value !== null && value !== void 0 ? value : null;
}

/**
 * Effect wrapper for Fetch API
 *
 * It's used to declare static type of Error and mock requests in tests
 */

const fetchFx = createEffect({
  sid: 'ff.fetchFx',
  handler: globalThis.fetch
});

/**
 * Basic request effect around fetchFx, with some additional features:
 * + it throws error if response status is 4XX/5XX
 * + it throws serializable NetworkError instead of TypeError
 */

const requestFx = createEffect({
  handler: async request => {
    var _a;

    const response = await fetchFx(request).catch(cause => {
      var _a;

      throw networkError({
        reason: (_a = cause === null || cause === void 0 ? void 0 : cause.message) !== null && _a !== void 0 ? _a : null,
        cause
      });
    });

    if (!response.ok) {
      throw httpError({
        status: response.status,
        statusText: response.statusText,
        response: (_a = await response.text().catch(() => null)) !== null && _a !== void 0 ? _a : null
      });
    }

    return response;
  },
  sid: 'ff.requestFx'
});

function createApiRequest(config) {
  var _a, _b;

  const prepareFx = createEffect(config.response.extract);
  const $haveToBeAborted = createStore(false, {
    serialize: 'ignore',
    name: 'ff.$haveToBeAborted',
    sid: 'ff.$haveToBeAborted'
  });
  const apiRequestFx = createEffect(async ({
    url,
    method,
    query,
    headers,
    credentials,
    body,
    onAbort,
    haveToBeAborted
  }) => {
    const abortController = new AbortController();
    onAbort(() => {
      abortController.abort();
    });

    if (haveToBeAborted) {
      throw abortError();
    }

    const mappedBody = body ? config.request.mapBody(body) : null;
    const request = new Request(formatUrl(url, query), {
      method,
      headers: formatHeaders(headers),
      credentials,
      body: mappedBody,
      signal: abortController.signal
    });
    const response = await requestFx(request).catch(cause => {
      if (config.response.transformError) {
        throw config.response.transformError(cause);
      }

      throw cause;
    }); // We cannot read body of the response twice (prepareFx and throw preparationError)

    const clonedResponse = response.clone();
    const prepared = await prepareFx(response).catch(async cause => {
      var _a;

      throw preparationError({
        response: await clonedResponse.text(),
        reason: (_a = cause === null || cause === void 0 ? void 0 : cause.message) !== null && _a !== void 0 ? _a : null
      });
    });

    if (config.response.status) {
      const expected = Array.isArray(config.response.status.expected) ? config.response.status.expected : [config.response.status.expected];

      if (!expected.includes(response.status)) {
        throw invalidDataError({
          validationErrors: [`Expected response status has to be one of [${expected.join(', ')}], got ${response.status}`],
          response: prepared
        });
      }
    }

    return prepared;
  });
  const boundApiRequestFx = attach({
    source: {
      url: normalizeStaticOrReactive(config.request.url),
      method: normalizeStaticOrReactive(config.request.method),
      query: normalizeStaticOrReactive(config.request.query),
      headers: normalizeStaticOrReactive(config.request.headers),
      credentials: normalizeStaticOrReactive(config.request.credentials),
      body: normalizeStaticOrReactive(config.request.body),
      haveToBeAborted: $haveToBeAborted
    },

    mapParams(dynamicConfig, staticConfig) {
      // Exclusive settings
      var _a, _b, _c;

      const url = (_a = staticConfig.url) !== null && _a !== void 0 ? _a : // @ts-expect-error TS cannot infer type correctly, but there is always field in staticConfig or dynamicConfig
      dynamicConfig.url;
      const credentials = (_b = staticConfig.credentials) !== null && _b !== void 0 ? _b : // @ts-expect-error TS cannot infer type correctly, but there is always field in staticConfig or dynamicConfig
      dynamicConfig.credentials;
      const body = (_c = staticConfig.body) !== null && _c !== void 0 ? _c : // @ts-expect-error TS cannot infer type correctly, but there is always field in staticConfig or dynamicConfig
      dynamicConfig.body; // Inclusive settings

      const query = mergeQueryStrings(staticConfig.query, dynamicConfig.query);
      const headers = mergeRecords(staticConfig.headers, dynamicConfig.headers); // Other settings

      const {
        method,
        haveToBeAborted
      } = staticConfig;
      const {
        onAbort
      } = dynamicConfig;
      return {
        url,
        method: method,
        query,
        headers,
        credentials,
        body,
        onAbort,
        haveToBeAborted
      };
    },

    effect: apiRequestFx
  });
  const abortSignal = createEvent();
  const boundAbortableApiRequestFx = abortable({
    abort: {
      signal: abortSignal
    },

    effect(params, abortContext) {
      return boundApiRequestFx(_extends({}, params, abortContext));
    }

  }); // Apply concurrency and abort settings

  if ((_a = config.abort) === null || _a === void 0 ? void 0 : _a.clock) {
    sample({
      clock: config.abort.clock,
      target: abortSignal
    });
  }

  switch ((_b = config.concurrency) === null || _b === void 0 ? void 0 : _b.strategy) {
    case 'TAKE_LATEST':
      sample({
        clock: boundAbortableApiRequestFx,
        target: abortSignal
      });
      break;

    case 'TAKE_FIRST':
      sample({
        clock: apiRequestFx,
        fn: () => true,
        target: $haveToBeAborted
      });
      sample({
        clock: boundAbortableApiRequestFx.finally,
        fn: () => false,
        target: $haveToBeAborted
      });
      break;

  }

  return boundAbortableApiRequestFx;
}

function createJsonApiRequest(config) {
  var _a; // Add default application/json header to every request


  const $headers = combine({
    method: normalizeStaticOrReactive(config.request.method),
    headers: normalizeStaticOrReactive(config.request.headers)
  }, ({
    method,
    headers
  }) => // reversed merge order to allow any modifications in the user code
  mergeRecords({
    Accept: 'application/json',
    'Content-Type': ['GET', 'HEAD'].includes(method) ? undefined : 'application/json'
  }, headers));
  const jsonApiCallFx = createApiRequest(_extends({}, config, {
    request: _extends({}, config.request, {
      headers: $headers,
      // Serialize body to JSON-string
      mapBody: jsonBody => JSON.stringify(jsonBody)
    }),
    response: {
      extract: async response => {
        const emptyContent = await isEmptyResponse(response);

        if (emptyContent) {
          return null;
        }

        return response.json();
      },
      transformError: error => {
        if (!isHttpError({
          error
        })) {
          return error;
        }

        const errorAsHttpError = error;

        if (typeof errorAsHttpError.response !== 'string') {
          return errorAsHttpError;
        }

        try {
          const parsedError = JSON.parse(errorAsHttpError.response);
          return httpError({
            status: errorAsHttpError.status,
            statusText: errorAsHttpError.statusText,
            response: parsedError
          });
        } catch (e) {
          return errorAsHttpError;
        }
      },
      status: (_a = config.response) === null || _a === void 0 ? void 0 : _a.status
    }
  }));
  return jsonApiCallFx;
}

async function isEmptyResponse(response) {
  if (!response.body) {
    return true;
  }

  const headerAsEmpty = response.headers.get('Content-Length') === '0';

  if (headerAsEmpty) {
    return true;
  } // Clone response to read it
  // because response can be read only once


  const clonnedResponse = response.clone();
  const bodyAsText = await clonnedResponse.text();

  if (bodyAsText.length === 0) {
    return true;
  }

  return false;
}

function createJsonQuery(config) {
  var _a, _b, _c, _d, _e;

  const credentials = config.request.credentials; // Basement

  const requestFx = createJsonApiRequest({
    request: {
      method: config.request.method,
      credentials
    },
    concurrency: {
      strategy: (_b = (_a = config.concurrency) === null || _a === void 0 ? void 0 : _a.strategy) !== null && _b !== void 0 ? _b : 'TAKE_LATEST'
    },
    abort: {
      clock: (_c = config.concurrency) === null || _c === void 0 ? void 0 : _c.abort
    }
  });
  const headlessQuery = createHeadlessQuery({
    initialData: config.initialData,
    contract: (_d = config.response.contract) !== null && _d !== void 0 ? _d : unknownContract,
    mapData: (_e = config.response.mapData) !== null && _e !== void 0 ? _e : ({
      result
    }) => result,
    validate: config.response.validate,
    enabled: config.enabled,
    name: config.name,
    serialize: config.serialize,
    sourced: [config.request.url, config.request.body, config.request.headers, config.request.query],
    paramsAreMeaningless: true
  });

  headlessQuery.__.executeFx.use(attach({
    source: {
      partialUrl: normalizeSourced({
        field: config.request.url
      }),
      partialBody: normalizeSourced({
        field: config.request.body
      }),
      partialHeaders: normalizeSourced({
        field: config.request.headers
      }),
      partialQuery: normalizeSourced({
        field: config.request.query
      })
    },

    mapParams(params, {
      partialUrl,
      partialBody,
      partialHeaders,
      partialQuery
    }) {
      return {
        url: partialUrl(params),
        body: partialBody(params),
        headers: partialHeaders(params),
        query: partialQuery(params)
      };
    },

    effect: requestFx
  }));

  return _extends({}, headlessQuery, {
    __: _extends({}, headlessQuery.__, {
      executeFx: requestFx
    })
  });
}

const MutationSymbol = Symbol('Mutation');
function isMutation(value) {
  var _a;

  return ((_a = value === null || value === void 0 ? void 0 : value.__) === null || _a === void 0 ? void 0 : _a.kind) === MutationSymbol;
}

const _excluded$1 = ["params"];
function createHeadlessMutation(config) {
  const {
    name,
    enabled,
    contract,
    validate,
    mapData
  } = config;
  const operation = createRemoteOperation({
    name,
    serialize: 'ignore',
    enabled,
    kind: MutationSymbol,
    meta: null,
    contract,
    validate,
    mapData
  }); // -- Protocols --

  const unitShape = {
    pending: operation.$pending,
    start: operation.start
  };

  const unitShapeProtocol = () => unitShape; // Experimental API, won't be exposed as protocol for now


  const attachProtocol = ({
    source,
    mapParams
  }) => {
    const attachedMutation = createHeadlessMutation(config);

    attachedMutation.__.lowLevelAPI.dataSourceRetrieverFx.use(attach({
      source,
      mapParams: (_ref, sourceValue) => {
        let {
          params
        } = _ref,
            rest = _objectWithoutPropertiesLoose(_ref, _excluded$1);

        return _extends({
          params: mapParams ? mapParams(params, sourceValue) : params
        }, rest);
      },
      effect: operation.__.lowLevelAPI.dataSourceRetrieverFx
    }));

    return attachedMutation;
  }; // -- Public API --


  return {
    start: operation.start,
    started: readonly(operation.started),
    aborted: readonly(operation.aborted),
    $status: readonly(operation.$status),
    $idle: readonly(operation.$idle),
    $pending: readonly(operation.$pending),
    $succeeded: readonly(operation.$succeeded),
    $failed: readonly(operation.$failed),
    $finished: readonly(operation.$finished),
    $enabled: readonly(operation.$enabled),
    finished: {
      success: readonly(operation.finished.success),
      failure: readonly(operation.finished.failure),
      finally: readonly(operation.finished.finally),
      skip: readonly(operation.finished.skip)
    },
    __: _extends({}, operation.__, {
      experimentalAPI: {
        attach: attachProtocol
      }
    }),
    '@@unitShape': unitShapeProtocol
  };
}

function createMutation( // Use any because of overloads
// eslint-disable-next-line @typescript-eslint/no-explicit-any
config) {
  var _a;

  const mutation = createHeadlessMutation({
    name: config.name,
    enabled: config.enabled,
    contract: (_a = config.contract) !== null && _a !== void 0 ? _a : unknownContract,
    mapData: ({
      result
    }) => result
  });

  mutation.__.executeFx.use(resolveExecuteEffect(config));

  return mutation;
}

function createJsonMutation(config) {
  var _a, _b, _c;

  const credentials = config.request.credentials;
  const requestFx = createJsonApiRequest({
    request: {
      method: config.request.method,
      credentials
    },
    concurrency: {
      strategy: 'TAKE_EVERY'
    },
    response: {
      status: config.response.status
    },
    abort: {
      clock: (_a = config.concurrency) === null || _a === void 0 ? void 0 : _a.abort
    }
  });
  const headlessMutation = createHeadlessMutation({
    contract: (_b = config.response.contract) !== null && _b !== void 0 ? _b : unknownContract,
    mapData: (_c = config.response.mapData) !== null && _c !== void 0 ? _c : ({
      result
    }) => result,
    validate: config.response.validate,
    enabled: config.enabled,
    name: config.name
  });

  headlessMutation.__.executeFx.use(attach({
    source: {
      partialUrl: normalizeSourced({
        field: config.request.url
      }),
      partialBody: normalizeSourced({
        field: config.request.body
      }),
      partialHeaders: normalizeSourced({
        field: config.request.headers
      }),
      partialQuery: normalizeSourced({
        field: config.request.query
      })
    },

    mapParams(params, {
      partialUrl,
      partialBody,
      partialHeaders,
      partialQuery
    }) {
      return {
        url: partialUrl(params),
        body: partialBody(params),
        headers: partialHeaders(params),
        query: partialQuery(params)
      };
    },

    effect: requestFx
  }));

  return _extends({}, headlessMutation, {
    __: _extends({}, headlessMutation.__, {
      executeFx: requestFx
    })
  });
}

const millisecondUnits = ['ms', 'milli', 'millisecond', 'milliseconds'];
const secUnits = ['s', 'sec', 'secs', 'second', 'seconds'];
const minUnits = ['m', 'min', 'mins', 'minute', 'minutes'];
const hourUnits = ['h', 'hr', 'hrs', 'hour', 'hours'];
function parseTime(time) {
  if (typeof time === 'number') {
    return time;
  }

  let result = 0;

  for (const part of time.split(' ')) {
    switch (true) {
      case hasEnding(part, millisecondUnits):
        result += parseNumber(part);
        break;

      case hasEnding(part, secUnits):
        result += parseNumber(part) * 1000;
        break;

      case hasEnding(part, minUnits):
        result += parseNumber(part) * 60000;
        break;

      case hasEnding(part, hourUnits):
        result += parseNumber(part) * 3600000;
        break;
    }
  }

  return result;
}

function hasEnding(value, allowedEndings) {
  return allowedEndings.includes(extractNonNumeric(value));
}

function extractNonNumeric(value) {
  return value.replace(/[0-9.]/g, '');
}

function parseNumber(value) {
  return value.includes('.') ? parseFloat(value) : parseInt(value);
}

const _excluded = ["times", "delay", "filter", "mapParams"],
      _excluded2 = ["supressError"];
function retry(operation, _ref) {
  let {
    times,
    delay: timeout,
    filter,
    mapParams
  } = _ref,
      params = _objectWithoutPropertiesLoose(_ref, _excluded);

  var _a;

  const supressIntermediateErrors = (_a = params.supressIntermediateErrors) !== null && _a !== void 0 ? _a : true;
  const $maxAttempts = normalizeStaticOrReactive(times);
  const $attempt = createStore(1, {
    serialize: 'ignore',
    name: 'ff.$attempt',
    sid: 'ff.$attempt'
  });
  const $meta = combine({
    attempt: $attempt
  });
  const $supressError = combine($attempt, $maxAttempts, (attempt, maxAttempts) => supressIntermediateErrors && attempt <= maxAttempts);
  const failed = createEvent();
  const newAttempt = createEvent();
  const {
    planNextAttempt,
    __: retriesAreOver
  } = split(sample({
    clock: failed,
    source: {
      maxAttempts: $maxAttempts,
      attempt: $attempt,
      partialFilter: normalizeSourced({
        field: filter !== null && filter !== void 0 ? filter : true
      })
    },
    filter: ({
      partialFilter
    }, clock) => partialFilter(clock),
    fn: ({
      attempt,
      maxAttempts
    }, {
      params,
      error,
      meta
    }) => ({
      params,
      error,
      meta: _extends({}, meta, {
        attempt,
        maxAttempts
      })
    })
  }), {
    planNextAttempt: ({
      meta
    }) => meta.attempt <= meta.maxAttempts
  });
  sample({
    clock: delay({
      clock: sample({
        clock: planNextAttempt,
        source: {
          partialMapper: normalizeSourced({
            field: mapParams !== null && mapParams !== void 0 ? mapParams : ({
              params
            }) => params
          })
        },
        fn: ({
          partialMapper
        }, clock) => partialMapper(clock)
      }),
      timeout: combine({
        partialTimeout: normalizeSourced({
          field: timeout
        }),
        meta: $meta
      }, ({
        partialTimeout,
        meta
      }) => parseTime(partialTimeout(meta)))
    }),
    fn: params => ({
      params,
      meta: {
        stopErrorPropagation: false,
        stale: true
      }
    }),
    target: [newAttempt, operation.__.lowLevelAPI.startWithMeta]
  });
  $attempt.on(newAttempt, attempt => attempt + 1).reset([operation.finished.success, operation.start]);

  if (params.otherwise) {
    sample({
      clock: retriesAreOver,
      target: params.otherwise
    });
  }

  if (supressIntermediateErrors) {
    const originalFx = operation.__.lowLevelAPI.dataSourceRetrieverFx.use.getCurrent();

    operation.__.lowLevelAPI.dataSourceRetrieverFx.use(attach({
      source: $supressError,
      mapParams: (opts, supressError) => _extends({}, opts, {
        supressError
      }),
      effect: createEffect(async _ref2 => {
        let {
          supressError
        } = _ref2,
            opts = _objectWithoutPropertiesLoose(_ref2, _excluded2);

        const boundFailed = scopeBind(failed, {
          safe: true
        });

        try {
          const result = await originalFx(opts);
          return result;
        } catch (error) {
          if (supressError) {
            boundFailed({
              params: opts.params,
              error: error.error,
              meta: opts.meta
            });
            throw {
              error: error.error,
              stopErrorPropagation: true
            };
          } else {
            throw error;
          }
        }
      })
    }));
  }

  sample({
    clock: operation.finished.failure,
    target: failed
  });
}

const defaultOptions = {
  randomize: {
    spread: 0
  }
};
function linearDelay(base, opts = defaultOptions) {
  return function ({
    attempt
  }) {
    return base * attempt + randomAddition(opts);
  };
}
function exponentialDelay(base, opts = defaultOptions) {
  return function ({
    attempt
  }) {
    return base ** attempt + randomAddition(opts);
  };
}

function randomAddition({
  randomize
}) {
  const {
    spread
  } = randomize;
  return randomNumber({
    min: -spread,
    max: spread
  });
}

/**
 *
 * Applies timeout to the operation - if operation is not finished in specified time, it will be aborted
 *
 * @param operation - Any remote operation, like Query or Mutation
 * @param config - Timeout config
 * @param config.after - Time after which operation will be aborted, can be human-readable string (like "100ms") or number in milliseconds, or effector's `Store` with any of these types
 */

function timeout(operation, config) {
  const timeoutAbortFx = attach({
    source: normalizeStaticOrReactive(config.after).map(parseTime),

    effect(timeoutMs, callObj) {
      return new Promise(resolve => {
        var _a; // Setup call abort by timeout


        const timeout = setTimeout(() => {
          callObj.abort(timeoutError({
            timeout: timeoutMs
          }));
          resolve();
        }, timeoutMs); // Setup timeout cleanup if call is finished before timeout

        const cleanup = () => {
          clearTimeout(timeout);
          resolve();
        };

        (_a = callObj.promise) === null || _a === void 0 ? void 0 : _a.then(cleanup, cleanup);
      });
    }

  });
  sample({
    clock: operation.__.lowLevelAPI.callObjectCreated,
    target: timeoutAbortFx
  });
}

function update(query, {
  on: mutation,
  by: rules
}) {
  const $queryState = queryState(query);
  const fillQueryData = createEvent();
  const fillQueryError = createEvent();
  split({
    source: sample({
      clock: mutation.finished.success,
      source: {
        partialRule: normalizeSourced({
          field: rules.success
        }),
        queryState: $queryState
      },
      fn: ({
        partialRule,
        queryState
      }, mutation) => partialRule({
        query: queryState,
        mutation
      })
    }),
    match: {
      fillData: payload => isNotEmpty(payload.result)
    },
    cases: {
      fillData: fillQueryData,
      __: fillQueryError
    }
  });

  if (rules.failure) {
    split({
      source: sample({
        clock: mutation.finished.failure,
        source: {
          partialRule: normalizeSourced({
            field: rules.failure
          }),
          queryState: $queryState
        },
        fn: ({
          partialRule,
          queryState
        }, mutation) => partialRule({
          query: queryState,
          mutation
        })
      }),
      match: {
        fillData: payload => isNotEmpty(payload.result)
      },
      cases: {
        fillData: fillQueryData,
        __: fillQueryError
      }
    });
  }

  sample({
    clock: fillQueryData,
    fn: ({
      result
    }) => result,
    target: query.__.lowLevelAPI.pushData
  });
  sample({
    clock: fillQueryError,
    fn: ({
      error
    }) => error,
    target: query.__.lowLevelAPI.pushError
  }); // -- Refetching

  const {
    shouldRefetch,
    __: shouldNotRefetch
  } = split(merge([fillQueryData, fillQueryError]).map(({
    refetch
  }) => refetch), {
    shouldRefetch: refetch => Boolean(refetch)
  });
  sample({
    clock: shouldRefetch,
    source: $queryState,
    filter: (state, refetch) => typeof refetch === 'object' && 'params' in refetch || state && 'params' in state,
    fn: (state, refetch) => {
      if (typeof refetch === 'object' && 'params' in refetch) {
        return {
          params: refetch.params,
          refresh: true
        };
      } // @ts-expect-error I do not want to fight with TS here


      return {
        params: state === null || state === void 0 ? void 0 : state.params,
        refresh: true
      };
    },
    target: [query.__.lowLevelAPI.revalidate, query.$stale.reinit]
  });
  sample({
    clock: shouldNotRefetch,
    source: $queryState,
    filter: state => state && 'params' in state,
    fn: state => ({
      params: state.params,
      refresh: false
    }),
    target: query.__.lowLevelAPI.revalidate
  });
}

function queryState(query) {
  return combine({
    idle: query.$idle,
    result: query.$data,
    params: query.__.$latestParams,
    error: query.$error,
    failed: query.$failed
  }, ({
    idle,
    result,
    params,
    error,
    failed
  }) => {
    if (result == null && error == null) {
      return null;
    }

    if (idle) {
      return {
        result
      };
    }

    if (failed) {
      return {
        error,
        params
      };
    }

    return {
      result,
      params
    };
  });
}

function attachOperation(operation, config) {
  var _a;

  const {
    source,
    mapParams
  } = config !== null && config !== void 0 ? config : {};
  return (_a = operation.__.experimentalAPI) === null || _a === void 0 ? void 0 : _a.attach({
    source: source !== null && source !== void 0 ? source : createStore(null, {
      serialize: 'ignore'
    }),
    mapParams: mapParams !== null && mapParams !== void 0 ? mapParams : v => v
  });
}

function createCacheAdapter(adapter) {
  const $instance = createStore(adapter, {
    serialize: 'ignore',
    name: 'ff.$cacheInstance',
    sid: 'ff.$cacheInstance'
  });
  return _extends({}, adapter, {
    __: {
      $instance
    }
  });
}

function attachObservability({
  adapter,
  options,
  events
}) {
  if (options === null || options === void 0 ? void 0 : options.hit) {
    sample({
      clock: adapter.get.done,
      filter: ({
        result
      }) => result !== null,
      fn: ({
        params
      }) => ({
        key: params.key
      }),
      target: options.hit
    });
  }

  if (options === null || options === void 0 ? void 0 : options.miss) {
    sample({
      clock: adapter.get.done,
      filter: ({
        result
      }) => result === null,
      fn: ({
        params
      }) => ({
        key: params.key
      }),
      target: options.miss
    });
  }

  if ((options === null || options === void 0 ? void 0 : options.expired) && (events === null || events === void 0 ? void 0 : events.itemExpired)) {
    sample({
      clock: events.itemExpired,
      fn: ({
        key
      }) => ({
        key
      }),
      target: options.expired
    });
  }

  if ((options === null || options === void 0 ? void 0 : options.evicted) && (events === null || events === void 0 ? void 0 : events.itemEvicted)) {
    sample({
      clock: events.itemEvicted,
      target: options.evicted
    });
  }
}

function inMemoryCache(config) {
  const {
    maxEntries,
    maxAge,
    observability
  } = config !== null && config !== void 0 ? config : {};
  let storage = {};
  const saveValue = createEvent();
  const removeValue = createEvent();
  const itemExpired = createEvent();
  const itemEvicted = createEvent();
  const purge = createEvent();
  purge.watch(() => {
    storage = {};
  });
  const $now = time({
    clock: saveValue
  });
  const maxEntriesApplied = sample({
    clock: saveValue,
    source: {
      now: $now
    },
    fn: ({
      now
    }, {
      key,
      value
    }) => applyMaxEntries(storage, {
      key,
      entry: {
        value,
        cachedAt: now
      }
    }, maxEntries)
  });
  maxEntriesApplied.watch(({
    next
  }) => {
    storage = next;
  });
  sample({
    clock: maxEntriesApplied,
    filter: ({
      evicted
    }) => !!evicted,
    fn: ({
      evicted
    }) => ({
      key: evicted
    }),
    target: itemEvicted
  });
  removeValue.watch(({
    key
  }) => {
    const rest = _objectWithoutPropertiesLoose(storage, [key].map(_toPropertyKey));

    storage = rest;
  });

  if (maxAge) {
    const timeout = parseTime(maxAge);
    saveValue.watch(payload => {
      const boundItemExpired = scopeBind(itemExpired, {
        safe: true
      });
      setTimeout(() => boundItemExpired(payload), timeout);
    });
    sample({
      clock: itemExpired,
      fn: ({
        key
      }) => ({
        key
      }),
      target: removeValue
    });
  }

  const adapter = {
    get: createEffect(({
      key
    }) => {
      var _a;

      const saved = (_a = storage[key]) !== null && _a !== void 0 ? _a : null;

      if (!saved) {
        return null;
      }

      if (maxAge) {
        const expiredAt = (saved === null || saved === void 0 ? void 0 : saved.cachedAt) + parseTime(maxAge);

        if (Date.now() >= expiredAt) {
          removeValue({
            key
          });
          return null;
        }
      }

      return saved;
    }),
    set: createEffect(saveValue),
    unset: createEffect(removeValue),
    purge
  };
  attachObservability({
    adapter,
    options: observability,
    events: {
      itemExpired,
      itemEvicted
    }
  });
  return createCacheAdapter(adapter);
}

function applyMaxEntries(storage, {
  key,
  entry
}, maxEntries) {
  if (maxEntries === undefined) return {
    next: _extends({}, storage, {
      [key]: entry
    }),
    evicted: null
  };
  const keys = Object.keys(storage);
  if (keys.length < maxEntries) return {
    next: _extends({}, storage, {
      [key]: entry
    }),
    evicted: null
  };
  const [firstKey] = keys;

  const rest = _objectWithoutPropertiesLoose(storage, [firstKey].map(_toPropertyKey));

  return {
    next: _extends({}, rest, {
      [key]: entry
    }),
    evicted: firstKey
  };
}

// Copied from http://www.movable-type.co.uk/scripts/sha1.html

/**
 * Generates SHA-1 hash of string
 */
function sha1(source) {
  // convert string to UTF-8, as SHA only deals with byte-streams
  let msg = encodeUTF8(source); // constants [§4.2.1]

  const K = [0x5a827999, 0x6ed9eba1, 0x8f1bbcdc, 0xca62c1d6]; // PREPROCESSING

  msg += String.fromCharCode(0x80); // add trailing '1' bit (+ 0's padding) to string [§5.1.1]
  // convert string msg into 512-bit/16-integer blocks arrays of ints [§5.2.1]

  const l = msg.length / 4 + 2; // length (in 32-bit integers) of msg + ‘1’ + appended length

  const N = Math.ceil(l / 16); // number of 16-integer-blocks required to hold 'l' ints

  const M = new Array(N);

  for (let i = 0; i < N; i++) {
    M[i] = new Array(16);

    for (let j = 0; j < 16; j++) {
      // encode 4 chars per integer, big-endian encoding
      M[i][j] = msg.charCodeAt(i * 64 + j * 4) << 24 | msg.charCodeAt(i * 64 + j * 4 + 1) << 16 | msg.charCodeAt(i * 64 + j * 4 + 2) << 8 | msg.charCodeAt(i * 64 + j * 4 + 3);
    } // note running off the end of msg is ok 'cos bitwise ops on NaN return 0

  } // add length (in bits) into final pair of 32-bit integers (big-endian) [§5.1.1]
  // note: most significant word would be (len-1)*8 >>> 32, but since JS converts
  // bitwise-op args to 32 bits, we need to simulate this by arithmetic operators


  M[N - 1][14] = (msg.length - 1) * 8 / Math.pow(2, 32);
  M[N - 1][14] = Math.floor(M[N - 1][14]);
  M[N - 1][15] = (msg.length - 1) * 8 & 0xffffffff; // set initial hash value [§5.3.1]

  let H0 = 0x67452301;
  let H1 = 0xefcdab89;
  let H2 = 0x98badcfe;
  let H3 = 0x10325476;
  let H4 = 0xc3d2e1f0; // HASH COMPUTATION [§6.1.2]

  const W = new Array(80);
  let a, b, c, d, e;

  for (let i = 0; i < N; i++) {
    // 1 - prepare message schedule 'W'
    for (let t = 0; t < 16; t++) W[t] = M[i][t];

    for (let t = 16; t < 80; t++) W[t] = ROTL(W[t - 3] ^ W[t - 8] ^ W[t - 14] ^ W[t - 16], 1); // 2 - initialise five working variables a, b, c, d, e with previous hash value


    a = H0;
    b = H1;
    c = H2;
    d = H3;
    e = H4; // 3 - main loop

    for (let t = 0; t < 80; t++) {
      // seq for blocks of 'f' functions and 'K' constants
      const s = Math.floor(t / 20); // it is safe to use  0 | 1 | 2 | 3 because of max value of t is 79

      const T = ROTL(a, 5) + f(s, b, c, d) + e + K[s] + W[t] & 0xffffffff;
      e = d;
      d = c;
      c = ROTL(b, 30);
      b = a;
      a = T;
    } // 4 - compute the new intermediate hash value


    H0 = H0 + a & 0xffffffff; // note 'addition modulo 2^32'

    H1 = H1 + b & 0xffffffff;
    H2 = H2 + c & 0xffffffff;
    H3 = H3 + d & 0xffffffff;
    H4 = H4 + e & 0xffffffff;
  }

  return toHexString(H0) + toHexString(H1) + toHexString(H2) + toHexString(H3) + toHexString(H4);
} //
// function 'f' [§4.1.1]
//

function f(s, x, y, z) {
  switch (s) {
    case 0:
      return x & y ^ ~x & z;
    // Ch()

    case 1:
      return x ^ y ^ z;
    // Parity()

    case 2:
      return x & y ^ x & z ^ y & z;
    // Maj()

    case 3:
      return x ^ y ^ z;
    // Parity()
  }
}
/**
 * rotate left (circular left shift) value x by n positions [§3.2.5]
 */


function ROTL(x, n) {
  return x << n | x >>> 32 - n;
}
/**
 * hexadecimal representation of a number
 */


function toHexString(n) {
  let s = '';
  let v;

  for (let i = 7; i >= 0; i--) {
    v = n >>> i * 4 & 0xf;
    s += v.toString(16);
  }

  return s;
}
/**
 * Encode multi-byte Unicode string into utf-8 multiple single-byte characters
 * (BMP / basic multilingual plane only)
 *
 * Chars in range U+0080 - U+07FF are encoded in 2 chars, U+0800 - U+FFFF in 3 chars
 *
 * @param {String} unicodeString Unicode string to be encoded as UTF-8
 * @returns {String} encoded string
 */


function encodeUTF8(unicodeString) {
  return unicodeString.replace(/[\u0080-\u07ff]/g, // U+0080 - U+07FF => 2 bytes 110yyyyy, 10zzzzzz
  c => {
    const cc = c.charCodeAt(0);
    return String.fromCharCode(0xc0 | cc >> 6, 0x80 | cc & 0x3f);
  }).replace(/[\u0800-\uffff]/g, // U+0800 - U+FFFF => 3 bytes 1110xxxx, 10yyyyyy, 10zzzzzz
  function (c) {
    const cc = c.charCodeAt(0);
    return String.fromCharCode(0xe0 | cc >> 12, 0x80 | cc >> 6 & 0x3f, 0x80 | cc & 0x3f);
  });
}

function stableStringify(data) {
  const seen = new Set();

  function stringify(node) {
    if (node === undefined) return;
    if (node === null) return 'null';

    if (typeof node === 'number') {
      return isFinite(node) ? `${node}` : 'null';
    }

    if (typeof node === 'function') {
      throw new TypeError(`Can't serialize function`);
    }

    if (typeof node !== 'object') return JSON.stringify(node);

    if (seen.has(node)) {
      throw new TypeError(`Can't serialize cyclic structure`);
    }

    seen.add(node);

    if (Array.isArray(node)) {
      const _values = node.map(v => stringify(v) || 'null').join(',');

      seen.delete(node);
      return `[${_values}]`;
    }

    const values = Object.keys(node).sort().map(key => {
      // @ts-expect-error We're working with unknown object
      const value = stringify(node[key]);
      return value ? `${stringify(key)}:${value}` : '';
    }).filter(Boolean).join(',');
    seen.delete(node);
    return `{${values}}`;
  }

  return stringify(data);
}

function createKey({
  sid,
  params = null,
  sources
}) {
  try {
    const stableString = stableStringify({
      params,
      sources,
      sid
    });
    return sha1(stableString);
  } catch (e) {
    return null;
  }
}
function queryUniqId(query) {
  const sid = querySid(query);

  if (sid) {
    return sid;
  }

  const uniqName = queryUniqName(query);

  if (uniqName) {
    return uniqName;
  }

  throw new Error('Query does not have sid or uniq name, which is required for caching, read more https://farfetched.pages.dev/recipes/sids.html');
}

function querySid(query) {
  var _a;

  return (_a = query.__.meta.sid) !== null && _a !== void 0 ? _a : null;
}

const prevNames = new Set();

function queryUniqName(query) {
  const name = query.__.meta.name;

  if (prevNames.has(name)) {
    return null;
  }

  prevNames.add(name);
  return name;
}

function cache(query, rawParams) {
  var _a;

  const {
    adapter,
    staleAfter,
    purge
  } = _extends({
    adapter: (_a = rawParams === null || rawParams === void 0 ? void 0 : rawParams.adapter) !== null && _a !== void 0 ? _a : inMemoryCache()
  }, rawParams);

  const id = queryUniqId(query);

  const sourcedReaders = query.__.lowLevelAPI.sourced.map(createSourcedReader);

  const readAllSourcedFx = createEffect(async params => {
    return Promise.all(sourcedReaders.map(readerFx => readerFx(params)));
  });
  const unsetFx = createEffect(async ({
    instance,
    params
  }) => {
    const sources = await readAllSourcedFx(params);
    const key = createKey({
      sid: id,
      params: query.__.lowLevelAPI.paramsAreMeaningless ? null : params,
      sources
    });

    if (!key) {
      return;
    }

    await instance.unset({
      key
    });
  });
  const setFx = createEffect(async ({
    instance,
    params,
    result
  }) => {
    const sources = await readAllSourcedFx(params);
    const key = createKey({
      sid: id,
      params: query.__.lowLevelAPI.paramsAreMeaningless ? null : params,
      sources
    });

    if (!key) {
      return;
    }

    await instance.set({
      key,
      value: result
    });
  });
  const getFx = createEffect(async ({
    params,
    instance
  }) => {
    const sources = await readAllSourcedFx(params);
    const key = createKey({
      sid: id,
      params: query.__.lowLevelAPI.paramsAreMeaningless ? null : params,
      sources
    });

    if (!key) {
      return null;
    }

    const result = await instance.get({
      key
    });

    if (!result) {
      return null;
    }

    const stale = staleAfter ? result.cachedAt + parseTime(staleAfter) <= Date.now() : true;
    return {
      result: result.value,
      stale
    };
  });
  const cacheDatSource = {
    name: 'cache',
    get: attach({
      source: {
        instance: adapter.__.$instance
      },
      mapParams: ({
        params
      }, {
        instance
      }) => ({
        params,
        instance
      }),
      effect: getFx
    }),
    set: attach({
      source: {
        instance: adapter.__.$instance
      },
      mapParams: ({
        params,
        result
      }, {
        instance
      }) => ({
        params,
        result,
        instance
      }),
      effect: setFx
    }),
    unset: attach({
      source: {
        instance: adapter.__.$instance
      },
      mapParams: ({
        params
      }, {
        instance
      }) => ({
        instance,
        params
      }),
      effect: unsetFx
    })
  };

  query.__.lowLevelAPI.dataSources.unshift(cacheDatSource);

  if (purge) {
    sample({
      clock: purge,
      source: {
        instance: adapter.__.$instance
      },
      target: createEffect(({
        instance
      }) => instance.purge())
    });
  }
}

const META_KEY = '__farfetched_meta__';
function browserStorageCache(config) {
  const {
    storage,
    observability,
    maxAge,
    maxEntries,
    serialize
  } = config; // -- adapter

  function storageCache() {
    const getSavedItemFx = createEffect(async key => {
      const item = await getItemFx(key);
      if (!item) return null;

      try {
        const parsed = JSON.parse(item);
        return _extends({}, parsed, {
          value: (serialize === null || serialize === void 0 ? void 0 : serialize.read) ? serialize.read(parsed.value) : parsed.value
        });
      } catch (_a) {
        return null;
      }
    });
    const setSavedItemFx = createEffect(async ({
      key,
      value
    }) => {
      const item = JSON.stringify({
        value: (serialize === null || serialize === void 0 ? void 0 : serialize.write) ? serialize.write(value) : value,
        timestamp: Date.now()
      });
      metaStorage.addKey({
        key
      });
      await setItemFx({
        key,
        value: item
      });
    });
    const removeSavedItemFx = createEffect(async key => {
      metaStorage.removeKey({
        key
      });
      await removeItemFx(key);
    });
    const itemExpired = createEvent();
    const itemEvicted = createEvent();
    const purge = createEvent();
    const purgeFx = createEffect(async keys => Promise.all(keys.map(removeSavedItemFx)));
    sample({
      clock: purge,
      source: metaStorage.$meta,
      fn: meta => {
        var _a;

        return (_a = meta === null || meta === void 0 ? void 0 : meta.keys) !== null && _a !== void 0 ? _a : [];
      },
      target: purgeFx
    });

    if (maxAge) {
      sample({
        clock: delay({
          clock: sample({
            clock: setItemFx.done,
            filter: ({
              params
            }) => params.key !== META_KEY
          }),
          timeout: parseTime(maxAge)
        }),
        fn: get('params'),
        target: [itemExpired, removeSavedItemFx]
      });
    }

    const adapter = {
      get: createEffect(async ({
        key
      }) => {
        const saved = await getSavedItemFx(key);
        if (!saved) return null;

        if (maxAge) {
          const expiredAt = (saved === null || saved === void 0 ? void 0 : saved.timestamp) + parseTime(maxAge);

          if (Date.now() >= expiredAt) {
            itemExpired({
              key,
              value: saved.value
            });
            await removeSavedItemFx(key);
            return null;
          }
        }

        return {
          value: saved.value,
          cachedAt: saved.timestamp
        };
      }),
      set: createEffect(async ({
        key,
        value
      }) => {
        var _a, _b, _c;

        const meta = await getMetaFx();
        const keysAmount = (_b = (_a = meta === null || meta === void 0 ? void 0 : meta.keys) === null || _a === void 0 ? void 0 : _a.length) !== null && _b !== void 0 ? _b : 0;

        if (maxEntries && keysAmount >= maxEntries) {
          const forDelete = (_c = meta === null || meta === void 0 ? void 0 : meta.keys) === null || _c === void 0 ? void 0 : _c.slice(0, keysAmount - maxEntries + 1);

          for (const _key of forDelete !== null && forDelete !== void 0 ? forDelete : []) {
            itemEvicted({
              key: _key
            });
            await removeSavedItemFx(_key);
          }
        }

        await setSavedItemFx({
          key,
          value
        });
      }),
      unset: createEffect(async ({
        key
      }) => {
        await removeSavedItemFx(key);
      }),
      purge
    };
    attachObservability({
      adapter,
      options: observability,
      events: {
        itemExpired,
        itemEvicted
      }
    });
    return createCacheAdapter(adapter);
  } // -- meta storage


  const $meta = createStore(null, {
    serialize: 'ignore',
    name: 'ff.browserStorage.$meta',
    sid: 'ff.browserStorage.$meta'
  });
  const getMetaFx = createEffect(async () => {
    const meta = await getItemFx(META_KEY);
    if (!meta) return null;

    try {
      const parsed = JSON.parse(meta);
      return parsed;
    } catch (_a) {
      return null;
    }
  });
  const setMetaFx = createEffect(meta => setItemFx({
    key: META_KEY,
    value: JSON.stringify(meta)
  }));
  const addKey = createEvent();
  const removeKey = createEvent();
  const metaStorage = {
    $meta,
    addKey,
    removeKey
  };
  sample({
    clock: getMetaFx.doneData,
    target: $meta
  });
  sample({
    clock: $meta,
    filter: Boolean,
    target: setMetaFx
  });
  sample({
    clock: addKey,
    source: $meta,
    fn: (meta, {
      key
    }) => {
      var _a;

      const knownKeys = (_a = meta === null || meta === void 0 ? void 0 : meta.keys) !== null && _a !== void 0 ? _a : [];

      if (knownKeys.includes(key)) {
        return meta;
      }

      return _extends({}, meta, {
        keys: [...knownKeys, key]
      });
    },
    target: $meta
  });
  sample({
    clock: removeKey,
    source: $meta,
    fn: (meta, {
      key
    }) => {
      var _a, _b;

      return _extends({}, meta, {
        keys: (_b = (_a = meta === null || meta === void 0 ? void 0 : meta.keys) === null || _a === void 0 ? void 0 : _a.filter(k => k !== key)) !== null && _b !== void 0 ? _b : []
      });
    },
    target: $meta
  }); // -- storage effects

  const setItemFx = createEffect(params => {
    storage().setItem(params.key, params.value);
  });
  const getItemFx = createEffect(key => storage().getItem(key));
  const removeItemFx = createEffect(key => storage().removeItem(key)); // public

  return storageCache();
}

function localStorageCache(config) {
  return browserStorageCache(_extends({
    storage: () => localStorage
  }, config));
}

function sessionStorageCache(config) {
  return browserStorageCache(_extends({
    storage: () => sessionStorage
  }, config));
}

function voidCache() {
  return createCacheAdapter({
    get: createEffect(() => null),
    set: createEffect(() => {// pass
    }),
    purge: createEvent(),
    unset: createEffect()
  });
}

function declareParams() {
  return createEvent();
}

function keepFresh(query, config) {
  var _a;

  const triggers = [];
  const [triggerEvents, protocolCompatibleObjects] = divide((_a = config.triggers) !== null && _a !== void 0 ? _a : [], is.event);
  triggers.push(...triggerEvents);
  const enabledParamStores = [query.$enabled];

  if (config.enabled !== undefined) {
    enabledParamStores.push(config.enabled);
  }

  const $enabled = every({
    predicate: Boolean,
    stores: enabledParamStores
  });

  if (protocolCompatibleObjects.length > 0) {
    const triggersByProtocol = protocolCompatibleObjects.map(trigger => trigger['@@trigger']());
    const $alreadySetup = createStore(false, {
      serialize: 'ignore',
      name: 'ff.$alreadySetup',
      sid: 'ff.$alreadySetup'
    });
    const {
      setup,
      teardown
    } = createApi($alreadySetup, {
      setup: () => true,
      teardown: () => false
    });
    sample({
      clock: [query.finished.success, sample({
        clock: $enabled.updates,
        filter: $enabled
      })],
      filter: not($alreadySetup),
      target: [...triggersByProtocol.map(get('setup')), setup]
    });
    sample({
      clock: $enabled.updates,
      filter: and($alreadySetup, not($enabled)),
      target: [...triggersByProtocol.map(get('teardown')), teardown]
    });
    triggers.push(...triggersByProtocol.map(get('fired')));
  }

  if (config.automatically) {
    const finalyParams = query.finished.finally.map(get('params'));
    const $previousSources = createStore([], {
      serialize: 'ignore',
      name: 'ff.$previousSources',
      sid: 'ff.$previousSources'
    });
    const $partialSources = combine(query.__.lowLevelAPI.sourced.map(sourced => normalizeSourced({
      field: sourced
    }))); // @ts-expect-error I have no idea

    sample({
      clock: finalyParams,
      source: $partialSources,
      fn: (partialSources, clock) => partialSources.map(partialSource => partialSource(clock)),
      filter: $enabled,
      target: $previousSources
    });
    const $nextSources = createStore(null, {
      serialize: 'ignore',
      name: 'ff.$nextSources',
      sid: 'ff.$nextSources'
    });
    sample({
      // @ts-expect-error I have no idea
      clock: query.__.lowLevelAPI.sourced.map(extractSource).filter(is.store),
      source: {
        latestParams: query.__.$latestParams,
        partialSources: $partialSources
      },
      filter: not(query.$idle),
      fn: ({
        latestParams,
        partialSources
      }) => partialSources.map(partialSource => partialSource(latestParams)),
      target: $nextSources
    });
    triggers.push(sample({
      clock: [$nextSources.updates, $enabled.updates.filter({
        fn: Boolean
      })],
      source: [$nextSources, $previousSources],
      filter: ([next, prev]) => !isEqual(next, prev)
    }));
  }

  const forceFresh = sample({
    clock: triggers,
    filter: $enabled
  });
  sample({
    clock: forceFresh,
    filter: not(query.$idle),
    fn: () => true,
    target: query.$stale
  }); // @ts-expect-error TS cannot get that if query.$idle is false, then $latestParams is Params

  sample({
    clock: syncBatch(forceFresh),
    source: query.__.$latestParams,
    filter: not(query.$idle),
    target: query.refresh
  });
}

/**
 * Applies the Barrier to the Query or Mutation. After operation start it checks the Barrier .$active status and postpones the execution if the Barrier is active. After the Barrier is deactivated, it resumes the execution of the operation.
 *
 * @param operation Query or Mutation to apply Barrier to
 * @param config.barrier Barrier to apply
 */

function applyBarrier(operation, {
  barrier
}) {
  sample({
    clock: operation.started,
    target: barrier.__.touch
  });
  sample({
    clock: operation.finished.failure,
    target: barrier.__.operationFailed
  });
  sample({
    clock: barrier.activated,
    filter: operation.$failed,
    source: operation.__.$latestParams,
    fn: params => ({
      params,
      meta: {
        stopErrorPropagation: false,
        stale: false
      }
    }),
    target: operation.__.lowLevelAPI.startWithMeta
  });
  const blockerSourceFx = attach({
    source: {
      mutex: barrier.__.$mutex,
      active: barrier.$active
    },

    async effect({
      mutex
    }) {
      await (mutex === null || mutex === void 0 ? void 0 : mutex.waitForUnlock());
      return null;
    }

  });

  operation.__.lowLevelAPI.dataSources.unshift({
    name: 'barrier_blocker',
    get: blockerSourceFx
  });
}

function createBarrier({
  active,
  perform,
  activateOn,
  deactivateOn
}) {
  const $mutex = createStore(null, {
    serialize: 'ignore'
  });
  const activated = createEvent();
  const deactivated = createEvent();
  const touch = createEvent();
  sample({
    clock: touch,
    source: $mutex,
    filter: mutex => mutex === null,
    fn: () => new Mutex(),
    target: $mutex
  });
  sample({
    clock: activated,
    target: attach({
      source: $mutex,

      async effect(mutex) {
        await (mutex === null || mutex === void 0 ? void 0 : mutex.acquire());
      }

    })
  });
  sample({
    clock: deactivated,
    target: attach({
      source: $mutex,

      async effect(mutex) {
        mutex === null || mutex === void 0 ? void 0 : mutex.release();
      }

    })
  });
  const operationFailed = createEvent();
  const operationDone = createEvent();
  const performers = normalizePerformers(perform !== null && perform !== void 0 ? perform : []);
  let $active; // Overload: active

  if (active) {
    $active = active;
  } // Overload: activateOn/deactivateOn
  else if (is.event(activateOn) && is.event(deactivateOn)) {
    $active = createStore(false, {
      sid: 'barrier.$active',
      name: 'barrier.$active'
    }).on(activateOn, () => true).on(deactivateOn, () => false);
  } // Overload: activateOn only
  else if (activateOn) {
    $active = createStore(false, {
      sid: 'barrier.$active',
      name: 'barrier.$active'
    });

    if ('failure' in activateOn && activateOn.failure) {
      const callback = activateOn.failure;
      sample({
        clock: operationFailed,
        filter: ({
          error,
          params
        }) => callback({
          error,
          params
        }),
        fn: () => true,
        target: [$active, touch]
      });
      sample({
        clock: combineEvents({
          events: performers.map(get('end')),
          reset: operationFailed
        }),
        fn: () => false,
        target: $active
      });
    }
  } else {
    throw new Error('Invalid configuration of createBarrier');
  }

  split({
    clock: [$active, touch],
    source: $active,
    match: {
      activated: Boolean
    },
    cases: {
      activated,
      __: deactivated
    }
  });
  sample({
    clock: touch,
    filter: $active,
    target: startOnlyNotPending(performers)
  });
  return {
    $active: readonly($active),
    activated: readonly(activated),
    deactivated: readonly(deactivated),
    __: {
      touch,
      operationFailed,
      operationDone,
      $mutex
    }
  };
}

function startOnlyNotPending(performers) {
  const clock = createEvent();

  for (const {
    start,
    $pending
  } of performers) {
    // @ts-expect-error 😇😇😇
    sample({
      clock,
      filter: not($pending),
      target: start
    });
  }

  return clock;
}

function normalizePerformers(performers) {
  return performers.map(performer => {
    if (perforerIsRemoteOperation(performer)) {
      return {
        start: performer.start,
        end: toVoid(sample({
          clock: [performer.finished.success, performer.finished.skip]
        })),
        $pending: performer.$pending
      };
    } else if (performerIsEffect(performer)) {
      return {
        start: performer,
        end: toVoid(performer.done),
        $pending: performer.pending
      };
    } else {
      const $pending = createStore(false, {
        serialize: 'ignore'
      }).on(performer.start, () => true).on(performer.end, () => false);
      return _extends({}, performer, {
        $pending
      });
    }
  });
}

function perforerIsRemoteOperation(performer) {
  return isQuery(performer) || isMutation(performer);
}

function performerIsEffect(performer) {
  return is.effect(performer);
}

function toVoid(event) {
  return sample({
    clock: event,
    fn: () => {// pass
    }
  });
}

export { abortError, applyBarrier, attachOperation, cache, combineSourced, configurationError, connectQuery, createBarrier, createCacheAdapter, createHeadlessMutation, createHeadlessQuery, createJsonMutation, createJsonQuery, createMutation, createQuery, declareParams, exponentialDelay, fetchFx, httpError, inMemoryCache, invalidDataError, isHttpError, isHttpErrorCode, isInvalidDataError, isNetworkError, isPreparationError, isTimeoutError, keepFresh, linearDelay, localStorageCache, networkError, normalizeSourced, preparationError, retry, sessionStorageCache, timeout, timeoutError, unknownContract, update, voidCache };
